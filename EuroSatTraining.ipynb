{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irlM1G-IQj_Z",
        "outputId": "f29a939c-5b0a-44cb-a749-83765116307c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.5.7)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.3)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.22.4)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.0)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.7 snuggs-1.4.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchsummary\n",
        "!pip install rasterio\n",
        "!pip install torchmetrics\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import rasterio as rio\n",
        "\n",
        "import torchmetrics as tm\n",
        "\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER = '/content/drive/MyDrive/GIS_ML/EuroSATallBands'"
      ],
      "metadata": {
        "id": "5xf5yV3_M7Ip"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIUT0qLHQxUK",
        "outputId": "6d4c378e-51f0-402d-9115-e97d6f8b96cb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dimensions(input_dimensions, block_number):\n",
        "  x = input_dimensions\n",
        "  for i in range(1,block_number+1,1):\n",
        "    x = x/2\n",
        "  return int(x)"
      ],
      "metadata": {
        "id": "WCYRmElnQ6k1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_dimensions(128,4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_Q1WIo0ReGX",
        "outputId": "8863ef89-371e-4951-ac2e-1f7961d683b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, multiclasses, input_features, output_features, hidden_layers, max_pooled_dimension):\n",
        "    super().__init__()\n",
        "    self.multiclasses = multiclasses\n",
        "    self.input_features = input_features\n",
        "    self.output_features = output_features\n",
        "    self.hidden_layers = hidden_layers\n",
        "    self.max_pooled_dimension = max_pooled_dimension\n",
        "\n",
        "    self.cnn_layers = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_features, out_channels=output_features[0], kernel_size=(3,3), padding=1),\n",
        "        nn.BatchNorm2d(output_features[0]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(in_channels=output_features[0], out_channels=output_features[1], kernel_size=(3,3), padding=1),\n",
        "        nn.BatchNorm2d(output_features[1]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(in_channels=output_features[1], out_channels=output_features[2], kernel_size=(3,3), padding=1),\n",
        "        nn.BatchNorm2d(output_features[2]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.Conv2d(in_channels=output_features[2], out_channels=output_features[3], kernel_size=(3,3), padding=1),\n",
        "        nn.BatchNorm2d(output_features[3]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    self.fcn_layers = nn.Sequential(\n",
        "        nn.Linear(max_pooled_dimension*max_pooled_dimension*output_features[3], hidden_layers[0]),\n",
        "        nn.BatchNorm1d(hidden_layers[0]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(hidden_layers[0], hidden_layers[1]),\n",
        "        nn.BatchNorm1d(hidden_layers[1]),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(hidden_layers[1], multiclasses)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.cnn_layers(x)\n",
        "    x = x.view(-1, self.max_pooled_dimension*self.max_pooled_dimension*self.output_features[3])\n",
        "    x = self.fcn_layers(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ohuhugCoRhUt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(multiclasses=10,\n",
        "            input_features=10,\n",
        "            output_features=[10,20,30,40],\n",
        "            hidden_layers=[268,512],\n",
        "            max_pooled_dimension=get_dimensions(64,4)).to(device)"
      ],
      "metadata": {
        "id": "__Bdbyd2TG0Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA2qLk6PThl3",
        "outputId": "fac5fad7-d489-41e1-b465-905e86a0374e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (cnn_layers): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(20, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Conv2d(30, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fcn_layers): Sequential(\n",
              "    (0): Linear(in_features=640, out_features=268, bias=True)\n",
              "    (1): BatchNorm1d(268, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Linear(in_features=268, out_features=512, bias=True)\n",
              "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(FOLDER+\"/train.csv\")\n",
        "test = pd.read_csv(FOLDER+\"/test.csv\")\n",
        "val = pd.read_csv(FOLDER+\"/validation.csv\")\n",
        "\n",
        "# reduction of the data to perform faster calculations\n",
        "train = train.sample(frac=0.1,random_state=101)\n",
        "test = test.sample(frac=0.1,random_state=101)\n",
        "val = val.sample(frac=0.1,random_state=101)"
      ],
      "metadata": {
        "id": "ghud-UrpUZyC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EuroSatDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        super().__init__\n",
        "        self.df = df\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = FOLDER + '/' + self.df.iloc[index, 0]\n",
        "        label = self.df.iloc[index, 1]\n",
        "        label = np.array(label)\n",
        "        source = rio.open(image_name)\n",
        "        image = source.read()\n",
        "        source.close()\n",
        "        image = image.astype('float32')\n",
        "        image = image[[1,2,3,4,5,6,7,8,11,12], :, :]\n",
        "        image = torch.from_numpy(image)\n",
        "        label = torch.from_numpy(label)\n",
        "        label = label.long()\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "jQ7nuGNOVWq5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EuroSatDataSet(train)\n",
        "print(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF1ulshAYUgJ",
        "outputId": "b72b232b-368f-4f3a-9352-6b97a7fecc5c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, sampler=None,\n",
        "num_workers=0, pin_memory=False, drop_last=False)"
      ],
      "metadata": {
        "id": "YRaY1ShGYZYG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.binarystudy.com/2021/04/how-to-calculate-mean-standard-deviation-images-pytorch.html - function taken from this input\n",
        "def batch_mean_and_sd(loader, input_bands):\n",
        "\n",
        "    count = 0\n",
        "    fst_moment = torch.empty(input_bands)\n",
        "    snd_moment = torch.empty(input_bands)\n",
        "\n",
        "    for images, _ in loader:\n",
        "        b, c, h, w = images.shape\n",
        "        pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        sum_of_square = torch.sum(images ** 2,\n",
        "                                  dim=[0, 2, 3])\n",
        "        fst_moment = (count * fst_moment + sum_) / (count + pixels)\n",
        "        snd_moment = (count * snd_moment + sum_of_square) / (count + pixels)\n",
        "        count += pixels\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n",
        "    return mean,std"
      ],
      "metadata": {
        "id": "JRHEo1OVYk2g"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "band_stats = batch_mean_and_sd(train_dataloader, 10)"
      ],
      "metadata": {
        "id": "EaBf7LWyY9ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EuroSat(Dataset):\n",
        "\n",
        "    def __init__(self, df, image_mean, image_std, transform):\n",
        "        self.df = df\n",
        "        self.image_mean = image_mean\n",
        "        self.image_std = image_std\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_name = FOLDER + '/' + self.df.iloc[index, 0]\n",
        "        label = self.df.iloc[index, 1]\n",
        "        label = np.array(label)\n",
        "        source = rio.open(image_name)\n",
        "        image = source.read()\n",
        "        source.close()\n",
        "        image = image[[1,2,3,4,5,6,7,8,11,12], :, :]\n",
        "        image = np.subtract(image, self.image_mean)\n",
        "        image = np.divide(image, self.image_std)\n",
        "        image = image.astype('float32')\n",
        "        image = torch.from_numpy(image)\n",
        "        label = torch.from_numpy(label)\n",
        "        label = label.long()\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ],
      "metadata": {
        "id": "IAlCEKOiZDfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "band_means = np.array(band_stats[0].tolist())\n",
        "band_stds = np.array(band_stats[1].tolist())"
      ],
      "metadata": {
        "id": "nykBPaiEcrqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_mean = np.repeat(band_means[0], 64*64).reshape((64,64,1))\n",
        "for b in range(1,len(band_means)):\n",
        "    image_mean_2 = np.repeat(band_means[b], 64*64).reshape((64,64,1))\n",
        "    image_mean = np.dstack([image_mean, image_mean_2])\n",
        "image_mean = np.transpose(image_mean, (2,0,1))\n",
        "\n",
        "image_std = np.repeat(band_stds[0], 64*64).reshape((64,64,1))\n",
        "for b in range(1,len(band_stds)):\n",
        "    image_std_2 = np.repeat(band_stds[b], 64*64).reshape((64,64,1))\n",
        "    image_std = np.dstack([image_std, image_std_2])\n",
        "image_std = np.transpose(image_std, (2,0,1))"
      ],
      "metadata": {
        "id": "WG7c5LARm6LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_transformation = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(p=0.3),\n",
        "    transforms.RandomVerticalFlip(p=0.3),]\n",
        "    )"
      ],
      "metadata": {
        "id": "jTl3SmULo9a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EuroSat(train, image_mean, image_std, transform=simple_transformation)\n",
        "validation_dataset = EuroSat(val, image_mean, image_std, transform=None)"
      ],
      "metadata": {
        "id": "wto1mHdPpOVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, sampler=None,\n",
        "num_workers=0, pin_memory=False, drop_last=True)\n",
        "\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=32, shuffle=False, sampler=None,\n",
        "num_workers=0, pin_memory=False, drop_last=True)"
      ],
      "metadata": {
        "id": "sHwil-ZKpoNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "images, labels = batch\n",
        "print(f'Batch Image Shape: {images.shape}, Batch Label Shape: {labels.shape}')\n",
        "print(f'Batch Image Data Type: {images.dtype}, Batch Label Data Type: {labels.dtype}')\n",
        "print(f'Batch Image Band Means: {torch.mean(images, dim=(0,2,3))}')\n",
        "print(f'Batch Label Minimum: {torch.min(labels, dim=0)}, Batch Label Maximum: {torch.max(labels, dim=0)}')"
      ],
      "metadata": {
        "id": "O0H2JkCPpv4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = images[1]\n",
        "test_mask = labels[1]\n",
        "print(f'Image Shape: {test_image.shape}, Label Shape: {test_mask.shape}')\n",
        "print(f'Image Data Type: {test_image.dtype}, Label Data Type: {test_mask.dtype}')"
      ],
      "metadata": {
        "id": "eCvW_D1BqK8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_display(img, image_mean, image_std):\n",
        "    img = np.multiply(img, image_std)\n",
        "    img = np.add(img, image_mean)\n",
        "    image_vis = img[[2,1,0],:,:]\n",
        "    image_vis = image_vis.permute(1,2,0)\n",
        "    image_vis = (image_vis.numpy()/4000)*255\n",
        "    image_vis = image_vis.astype('uint8')\n",
        "    return image_vis\n",
        "\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "cover_types = {0: 'Annual Crop',\n",
        "1: 'Forest',\n",
        "2: 'Herb Veg',\n",
        "3: 'Highway',\n",
        "4: 'Industrial',\n",
        "5: 'Pasture',\n",
        "6: 'Perm Crop',\n",
        "7: 'Residential',\n",
        "8: 'River',\n",
        "9: 'SeaLake'}"
      ],
      "metadata": {
        "id": "NNqGIAxLqOzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axis = plt.subplots(4, 8, figsize=(15, 10))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "    with torch.no_grad():\n",
        "        image, label = images[i], labels[i]\n",
        "        ax.imshow(img_display(image, image_mean, image_std)) # add image\n",
        "        ax.set(title = f\"{cover_types[label.item()]}\") # add label\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "vxUns7PQtbro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "metadata": {
        "id": "P8Q9rxTDtjcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = tm.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "f1 = tm.F1Score(task=\"multiclass\", num_classes=10).to(device)\n",
        "kappa = tm.CohenKappa(task=\"multiclass\", num_classes=10).to(device)"
      ],
      "metadata": {
        "id": "Dpo2NYYYuGkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "saveFolder = ''"
      ],
      "metadata": {
        "id": "ZUR0jjJx6zUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_number = []\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "train_f1 = []\n",
        "train_kappa = []\n",
        "validation_loss = []\n",
        "validation_acc = []\n",
        "validation_f1 = []\n",
        "validation_kappa = []\n",
        "\n",
        "f1VMax = 0.0\n",
        "\n",
        "# Loop over epochs\n",
        "for epoch in range(1, epochs+1):\n",
        "    # Loop over training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
        "        # Get data and move to device\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Predict data\n",
        "        outputs = model(inputs)\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accT = acc(outputs, targets)\n",
        "        f1T = f1(outputs, targets)\n",
        "        kappaT = kappa(outputs, targets)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    # Accumulate metrics at end of training epoch\n",
        "    accT = acc.compute()\n",
        "    f1T = f1.compute()\n",
        "    kappaT = kappa.compute()\n",
        "\n",
        "    # Print Losses and metrics at end of each training epoch\n",
        "    print(f'Epoch: {epoch}, Training Loss: {loss.item():.4f}, Training Accuracy: {accT:.4f}, Training F1: {f1T:.4f}, Training Kappa: {kappaT:.4f}')\n",
        "\n",
        "    # Append results\n",
        "    epoch_number.append(epoch)\n",
        "    train_loss.append(loss.item())\n",
        "    train_acc.append(accT.detach().cpu().numpy())\n",
        "    train_f1.append(f1T.detach().cpu().numpy())\n",
        "    train_kappa.append(kappaT.detach().cpu().numpy())\n",
        "\n",
        "    # Reset metrics\n",
        "    acc.reset()\n",
        "    f1.reset()\n",
        "    kappa.reset()\n",
        "\n",
        "    # loop over validation batches\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(validation_dataloader):\n",
        "            # Get data and move to device\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Predict data\n",
        "            outputs = model(inputs)\n",
        "            # Calculate validation loss\n",
        "            loss_v = criterion(outputs, targets)\n",
        "\n",
        "            # Calculate metrics\n",
        "            accV = acc(outputs, targets)\n",
        "            f1V = f1(outputs, targets)\n",
        "            kappaV = kappa(outputs, targets)\n",
        "\n",
        "    # Accumulate metrics at end of validation epoch\n",
        "    accV = acc.compute()\n",
        "    f1V = f1.compute()\n",
        "    kappaV = kappa.compute()\n",
        "\n",
        "    # Print validation loss and metrics\n",
        "    print(f'Validation Loss: {loss_v.item():.4f}, Validation Accuracy: {accV:.4f}, Validation F1: {f1V:.4f}, Validation Kappa: {kappaV:.4f}')\n",
        "\n",
        "    # Append results\n",
        "    validation_loss.append(loss_v.item())\n",
        "    validation_acc.append(accV.detach().cpu().numpy())\n",
        "    validation_f1.append(f1V.detach().cpu().numpy())\n",
        "    validation_kappa.append(kappaV.detach().cpu().numpy())\n",
        "\n",
        "    # Reset metrics\n",
        "    acc.reset()\n",
        "    f1.reset()\n",
        "    kappa.reset()\n",
        "\n",
        "    # Save model if validation F1-score improves\n",
        "    f1V2 = f1V.detach().cpu().numpy()\n",
        "    if f1V2 > f1VMax:\n",
        "        f1VMax = f1V2\n",
        "        torch.save(model.state_dict(), saveFolder + 'eurosat_model.pt')\n",
        "        print(f'Model saved for epoch {epoch}.')"
      ],
      "metadata": {
        "id": "lUPHE07L63vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SeNum = pd.Series(epoch_number, name=\"epoch\")\n",
        "St_loss = pd.Series(train_loss, name=\"training_loss\")\n",
        "St_acc = pd.Series(train_acc, name=\"training_accuracy\")\n",
        "St_f1 = pd.Series(train_f1, name=\"training_f1\")\n",
        "St_kappa = pd.Series(train_kappa, name=\"training_kappa\")\n",
        "Sv_loss = pd.Series(validation_loss, name=\"val_loss\")\n",
        "Sv_acc = pd.Series(validation_acc, name=\"val_accuracy\")\n",
        "Sv_f1 = pd.Series(validation_f1, name=\"val_f1\")\n",
        "Sv_kappa = pd.Series(train_kappa, name=\"val_kappa\")\n",
        "results_df = pd.concat([SeNum, St_loss, St_acc, St_f1, St_kappa, Sv_loss, Sv_acc, Sv_f1, Sv_kappa], axis=1)"
      ],
      "metadata": {
        "id": "ei85ByI57VaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(saveFolder+\"resultsCNN.csv\")"
      ],
      "metadata": {
        "id": "5rxMI_4F76p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.read_csv(saveFolder+\"resultsCNN.csv\")"
      ],
      "metadata": {
        "id": "kLlIGmv78FqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "first_plot = results_df.plot(x='epoch', y=\"training_loss\")\n",
        "results_df.plot(x='epoch', y=\"val_loss\", ax=first_plot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CGUN6SYj8HDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "first_plot = results_df.plot(x=\"epoch\", y=\"training_f1\")\n",
        "results_df.plot(x='epoch', y=\"val_f1\", ax=first_plot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBY0SSA38Nad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01G3KGDE8KKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}